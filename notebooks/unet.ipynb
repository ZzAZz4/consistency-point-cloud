{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxsEpzXeKlYg",
        "outputId": "8b8de12c-8a56-4898-c648-1740a424267c"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "# Helper functions for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def visualize_mesh(pos, face):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.axes.xaxis.set_ticklabels([])\n",
        "    ax.axes.yaxis.set_ticklabels([])\n",
        "    ax.axes.zaxis.set_ticklabels([]) # type: ignore\n",
        "    ax.plot_trisurf(pos[:, 0], pos[:, 1], pos[:, 2], triangles=face.t(), antialiased=False)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_points(pos, c=None):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.axes.xaxis.set_ticklabels([])\n",
        "    ax.axes.yaxis.set_ticklabels([])\n",
        "    ax.axes.zaxis.set_ticklabels([]) # type: ignore\n",
        "    ax.scatter(pos[:, 0], pos[:, 1], pos[:, 2], c='blue' if c is None else c, s=3)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import numpy as np\n",
        "from torch_geometric.nn import knn\n",
        "from torch_scatter import scatter\n",
        "from torch_geometric.nn import Linear, MLP, PointTransformerConv, fps, knn, knn_graph, knn_interpolate\n",
        "from torch_geometric.utils import scatter\n",
        "import torch.nn.functional as F\n",
        "from itertools import pairwise\n",
        "import typing as ty\n",
        "from torch_geometric.typing import OptTensor, Adj\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, time_channels: int, hidden_channels: int|None = None, last_act: str = 'silu'):\n",
        "        super().__init__()\n",
        "        hidden_channels = hidden_channels or out_channels\n",
        "\n",
        "        self.input_fc = MLP([in_channels, in_channels], act='silu') \n",
        "        self.point_transformer = PointTransformerConv(\n",
        "            in_channels, hidden_channels,\n",
        "            pos_nn=MLP([3, 64, out_channels], norm=None, plain_last=False),\n",
        "            attn_nn=MLP([in_channels, 64, out_channels], norm=None, plain_last=False)\n",
        "        )\n",
        "        \n",
        "        self.time_fc = MLP([time_channels, hidden_channels], act='silu')\n",
        "        self.output_fc = MLP([hidden_channels, out_channels], act=last_act) \n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x: Tensor, t: Tensor, pos: Tensor, edge_index):\n",
        "        x = self.input_fc(x)\n",
        "        x = self.point_transformer(x, pos, edge_index)\n",
        "        x = self.output_fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransitionDown(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, ratio=0.5, k=16, act='silu'):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.ratio = ratio\n",
        "        self.mlp = MLP([in_channels, out_channels], plain_last=False, act=act)\n",
        "\n",
        "    def forward(self, x: Tensor, pos: Tensor, batch):\n",
        "        id_clusters = fps(pos, ratio=self.ratio, batch=batch)\n",
        "        sub_batch = batch[id_clusters] if batch is not None else None\n",
        "        id_k_neighbor = knn(pos, pos[id_clusters], k=self.k, batch_x=batch, batch_y=sub_batch)\n",
        "        x = self.mlp(x)\n",
        "        x_out = scatter(x[id_k_neighbor[1]], id_k_neighbor[0], dim=0, dim_size=id_clusters.size(0), reduce='max')\n",
        "        sub_pos, out = pos[id_clusters], x_out\n",
        "        return out, sub_pos, sub_batch\n",
        "\n",
        "\n",
        "\n",
        "class TransitionUp(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()     \n",
        "        self.mlp_sub = MLP([in_channels, out_channels], plain_last=False)\n",
        "        self.mlp = MLP([out_channels, out_channels], plain_last=False)                                        \n",
        "  \n",
        "    def forward(self, x, x_sub, pos, pos_sub, batch=None, batch_sub=None):\n",
        "        x_sub = self.mlp_sub(x_sub)                                                                           \n",
        "        x_interpolated = knn_interpolate(x_sub, pos_sub, pos, k=3, batch_x=batch_sub, batch_y=batch)                                    \n",
        "        x = self.mlp(x) + x_interpolated                                                                      \n",
        "  \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, time_channels: int, ratio: float=0.5, k=16):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.transition_down = TransitionDown(in_channels, out_channels, ratio, k, act='silu')\n",
        "        self.transformer = TransformerBlock(out_channels, out_channels, time_channels, last_act='silu')\n",
        "\n",
        "    def forward(self, x: Tensor, t: Tensor, pos: Tensor, batch: OptTensor=None):\n",
        "        x, pos, batch = self.transition_down(x=x, pos=pos, batch=batch)\n",
        "        edge_index = knn_graph(pos, k=self.k, batch=batch)\n",
        "        x = self.transformer(x=x, t=t[batch], pos=pos, edge_index=edge_index)\n",
        "        return x, pos, batch\n",
        "\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, time_channels: int, k: int=16, norm: str | None='batch_norm'):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.mlp = MLP([in_channels, out_channels], plain_last=False, norm=norm)\n",
        "        self.transformer = TransformerBlock(out_channels, out_channels, time_channels)\n",
        "\n",
        "    def forward(self, x: Tensor, t: Tensor, pos: Tensor, batch: OptTensor=None):\n",
        "        x = self.mlp(x)\n",
        "        edge_index = knn_graph(pos, k=self.k, batch=batch)\n",
        "        x = self.transformer(x=x, t=t[batch], pos=pos, edge_index=edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, time_channels):\n",
        "        super().__init__()\n",
        "        self.transition_up = TransitionUp(in_channels, out_channels)\n",
        "        self.transformer = TransformerBlock(out_channels, out_channels, time_channels)\n",
        "\n",
        "    def forward(self, x: Tensor, x_sub: Tensor, t: Tensor, pos: Tensor, pos_sub: Tensor, batch=None, batch_sub=None):\n",
        "        x = self.transition_up(x, x_sub, pos, pos_sub, batch, batch_sub)\n",
        "        edge_index = knn_graph(pos, k=16, batch=batch)\n",
        "        x = self.transformer(x=x, t=t[batch], pos=pos, edge_index=edge_index)\n",
        "        return x, pos, batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from embeddings import SigmaEmbedding, SigmaProjection\n",
        "\n",
        "\n",
        "class DenoisingUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        channels: int, \n",
        "        dim_model: tuple[int, ...], \n",
        "        k: int = 16\n",
        "    ):\n",
        "        super().__init__()\n",
        "        time_channels = 4 * dim_model[0]\n",
        "        self.time_projection = SigmaProjection(dim_model[0], True, 0)\n",
        "        self.time_embedding = SigmaEmbedding(dim_model[0], time_channels)\n",
        "\n",
        "        self.input_block = MLPBlock(in_channels=channels, out_channels=dim_model[0], time_channels=time_channels, k=k)\n",
        "        self.down_blocks = nn.ModuleList([\n",
        "            DownBlock(in_channels=upper, out_channels=lower, time_channels=time_channels, ratio=0.5, k=k) \n",
        "                for upper, lower in pairwise(dim_model)])\n",
        "        \n",
        "        self.summit_block = MLPBlock(in_channels=dim_model[-1], out_channels=dim_model[-1], time_channels=time_channels, k=k, norm=None)\n",
        "        self.up_blocks = nn.ModuleList([\n",
        "            UpBlock(in_channels=lower, out_channels=upper, time_channels=time_channels) \n",
        "                for lower, upper in pairwise(reversed(dim_model))])\n",
        "        \n",
        "        self.mlp_output = MLP([dim_model[0], 64, channels], norm=None, act='tanh')\n",
        "\n",
        "\n",
        "    def forward(self, pos: Tensor, t: Tensor, batch: OptTensor=None):\n",
        "        t = self.time_projection(t)\n",
        "        t = self.time_embedding(t)\n",
        "        \n",
        "        x: Tensor\n",
        "        x = self.input_block(x=pos, t=t, pos=pos, batch=batch)\n",
        "\n",
        "        left_outputs = [] \n",
        "        for down_block in self.down_blocks:\n",
        "            left_outputs.append((x, pos, batch))\n",
        "            x, pos, batch = down_block(x=x, t=t, pos=pos, batch=batch)\n",
        "            \n",
        "        x = self.summit_block(x=x, t=t, pos=pos, batch=batch) \n",
        "\n",
        "        for up_block, left_output in zip(self.up_blocks, reversed(left_outputs)):\n",
        "            left_x, left_pos, left_batch = left_output\n",
        "            x, pos, batch = up_block(x=left_x, x_sub=x, t=t, pos=left_pos, pos_sub=pos, batch=left_batch, batch_sub=batch)\n",
        "        \n",
        "        x = self.mlp_output(x)\n",
        "        return x\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import ShapeNet\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "path = \"data/ShapeNet\"\n",
        "category = 'Airplane' \n",
        "transform = T.Compose([\n",
        "    T.FixedPoints(1024),\n",
        "    T.RandomRotate(15, axis=0),\n",
        "    T.RandomRotate(15, axis=1),\n",
        "    T.RandomRotate(15, axis=2),\n",
        "])\n",
        "pre_transform = T.NormalizeScale()\n",
        "train_dataset = ShapeNet(path, category, split='trainval', transform=transform, pre_transform=pre_transform)\n",
        "test_dataset = ShapeNet(path, category, split='test', pre_transform=pre_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytorch3d.loss import chamfer_distance\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch import nn\n",
        "\n",
        "class CDLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target, batch):\n",
        "        pred, target = to_dense_batch(pred, batch)[0], to_dense_batch(target, batch)[0]\n",
        "        return chamfer_distance(pred, target, batch_reduction=None)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = next(iter(train_loader))\n",
        "pos, batch = sample.pos, sample.batch\n",
        "\n",
        "loss = CDLoss()\n",
        "loss.forward(pos, pos + 1.0, batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from consistency_models import ConsistencyTraining, timesteps_schedule, ema_decay_rate_schedule, update_ema_model\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "online_model = DenoisingUNet(channels=3, dim_model=(32, 64, 128, 256)).to(device)\n",
        "ema_model = DenoisingUNet(channels=3, dim_model=(32, 64, 128, 256)).to(device)\n",
        "ema_model.load_state_dict(online_model.state_dict())\n",
        "\n",
        "consistency_step = ConsistencyTraining()\n",
        "optimizer = torch.optim.Adam(online_model.parameters(), lr=0.0001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "\n",
        "online_model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "k = 0\n",
        "max_iters = 500 * len(train_loader)\n",
        "for epoch in range(1, 500):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        next_x, current_x = consistency_step(online_model, ema_model, data.pos, data.batch, k, max_iters)\n",
        "        \n",
        "        loss = loss_fn(next_x, current_x)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f'Epoch: {epoch}, Subepoch: {i} Loss: {loss.item()}')\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            visualize_points(current_x.detach().cpu().numpy())\n",
        "            visualize_points(next_x.detach().cpu().numpy())\n",
        "\n",
        "        with torch.no_grad():\n",
        "            num_timesteps = timesteps_schedule(epoch, 500)\n",
        "            ema_decay_rate = ema_decay_rate_schedule(num_timesteps,)\n",
        "            ema_model = update_ema_model(ema_model, online_model, ema_decay_rate)\n",
        "            \n",
        "        k += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
