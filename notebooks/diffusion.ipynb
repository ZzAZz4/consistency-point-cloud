{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, SiLU, ModuleList\n",
    "from torch_geometric.nn import MessagePassing, MLP, AttentionalAggregation, MaxAggregation\n",
    "from torch_geometric.nn import PointNetConv, PositionalEncoding\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "from torch_cluster import knn_graph, fps\n",
    "\n",
    "\n",
    "class PointNetEncoder(torch.nn.Module):\n",
    "    def __init__(self, zdim):\n",
    "        super().__init__()\n",
    "        self.conv1 = PointNetConv(\n",
    "            local_nn=MLP([3 + 3, 32], act=SiLU(), plain_last=True), \n",
    "            global_nn=SiLU(), \n",
    "            aggr=MaxAggregation()\n",
    "        )\n",
    "        self.conv2 = PointNetConv(\n",
    "            local_nn=MLP([32 + 3, 32], act=SiLU(), plain_last=True), \n",
    "            global_nn=SiLU(), \n",
    "            aggr=MaxAggregation()\n",
    "        )\n",
    "        self.aggr = MaxAggregation()\n",
    "        self.net = Linear(32, zdim)\n",
    "\n",
    "    def forward(self, pos: torch.Tensor, batch: torch.Tensor):\n",
    "        h: torch.Tensor\n",
    "        edge_index = knn_graph(pos, k=16, batch=batch, loop=True)\n",
    "        h = self.conv1(x=pos, pos=pos, edge_index=edge_index)\n",
    "\n",
    "        index = fps(pos, batch, ratio=0.5)\n",
    "        h, pos, batch = h[index], pos[index], batch[index]\n",
    "        edge_index = knn_graph(pos, k=16, batch=batch, loop=True)\n",
    "        h = self.conv2(x=h, pos=pos, edge_index=edge_index)\n",
    "\n",
    "        h = self.aggr(h, batch)  # [batch_size, hidden_channels]\n",
    "        return self.net(h)\n",
    "    \n",
    "\n",
    "class ConcatSquashLinear(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, dim_ctx):\n",
    "        super(ConcatSquashLinear, self).__init__()\n",
    "        self._layer = Linear(dim_in, dim_out)\n",
    "        self._hyper_bias = Linear(dim_ctx, dim_out, bias=False)\n",
    "        self._hyper_gate = Linear(dim_ctx, dim_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, ctx: torch.Tensor, batch: torch.Tensor):\n",
    "        gate: torch.Tensor = torch.sigmoid(self._hyper_gate(ctx))\n",
    "        bias: torch.Tensor = self._hyper_bias(ctx)\n",
    "        ret: torch.Tensor = self._layer(x) * gate[batch] + bias[batch]\n",
    "        return ret\n",
    "\n",
    "\n",
    "class PointwiseNet(torch.nn.Module):\n",
    "    def __init__(self, dim_ctx):\n",
    "        super().__init__()\n",
    "        self.embedding = PositionalEncoding(dim_ctx)\n",
    "        self.net = ModuleList([\n",
    "            ConcatSquashLinear(3, 128, dim_ctx + dim_ctx),\n",
    "            ConcatSquashLinear(128, 256, dim_ctx + dim_ctx),\n",
    "            ConcatSquashLinear(256, 512, dim_ctx + dim_ctx),\n",
    "            ConcatSquashLinear(512, 256, dim_ctx + dim_ctx),\n",
    "            ConcatSquashLinear(256, 128, dim_ctx + dim_ctx),\n",
    "        ])\n",
    "        self.out = ConcatSquashLinear(128, 3, dim_ctx + dim_ctx)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, ctx: torch.Tensor, t: torch.Tensor, batch: torch.Tensor):\n",
    "        ctx2 = self.embedding(t)\n",
    "        ctx = torch.cat([ctx, ctx2], dim=-1)\n",
    "        \n",
    "        out: torch.Tensor = x\n",
    "        for layer in self.net:\n",
    "            out = layer(out, ctx, batch)\n",
    "            out = torch.nn.functional.silu(out)\n",
    "\n",
    "        out = self.out(out, ctx, batch)\n",
    "        return x + out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import GeometricShapes\n",
    "from torch_geometric.transforms import NormalizeScale, SamplePoints, Compose\n",
    "\n",
    "transform = Compose([NormalizeScale(), SamplePoints(1024)])\n",
    "dataset = GeometricShapes(root='data/GeometricShapes', transform=transform)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "path = \"data/ShapeNet\"\n",
    "category = 'Airplane' \n",
    "transform = T.Compose([\n",
    "    T.FixedPoints(1024),\n",
    "    # T.RandomRotate(15, axis=0),\n",
    "    # T.RandomRotate(15, axis=1),\n",
    "    # T.RandomRotate(15, axis=2),\n",
    "])\n",
    "pre_transform = T.NormalizeScale()\n",
    "train_dataset = ShapeNet(path, category, split='trainval', transform=transform, pre_transform=pre_transform)\n",
    "test_dataset = ShapeNet(path, category, split='test', transform=transform, pre_transform=pre_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=24, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class VarianceSchedule(torch.nn.Module):\n",
    "    def __init__(self, num_steps, beta_1, beta_T):\n",
    "        super().__init__()\n",
    "        self.num_steps = num_steps\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_T = beta_T\n",
    "\n",
    "        betas = torch.linspace(beta_1, beta_T, steps=num_steps)\n",
    "        betas = torch.cat([torch.zeros([1]), betas], dim=0)     # Padding\n",
    "\n",
    "        alphas = 1 - betas\n",
    "        log_alphas = torch.log(alphas)\n",
    "        for i in range(1, log_alphas.size(0)):  # 1 to T\n",
    "            log_alphas[i] += log_alphas[i - 1]\n",
    "        alpha_bars = log_alphas.exp()\n",
    "\n",
    "        sigmas_flex = torch.sqrt(betas)\n",
    "        sigmas_inflex = torch.zeros_like(sigmas_flex)\n",
    "        for i in range(1, sigmas_flex.size(0)):\n",
    "            sigmas_inflex[i] = ((1 - alpha_bars[i-1]) / (1 - alpha_bars[i])) * betas[i]\n",
    "        sigmas_inflex = torch.sqrt(sigmas_inflex)\n",
    "\n",
    "        self.betas: torch.Tensor\n",
    "        self.alphas: torch.Tensor\n",
    "        self.alpha_bars: torch.Tensor\n",
    "        self.sigmas_flex: torch.Tensor\n",
    "        self.sigmas_inflex: torch.Tensor\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alpha_bars', alpha_bars)\n",
    "        self.register_buffer('sigmas_flex', sigmas_flex)\n",
    "        self.register_buffer('sigmas_inflex', sigmas_inflex)\n",
    "\n",
    "    def uniform_sample_t(self, batch_size):\n",
    "        ts = np.random.choice(np.arange(1, self.num_steps+1), batch_size)\n",
    "        return ts.tolist()\n",
    "\n",
    "    def get_sigmas(self, t, flexibility):\n",
    "        assert 0 <= flexibility and flexibility <= 1\n",
    "        sigmas = self.sigmas_flex[t] * flexibility + self.sigmas_inflex[t] * (1 - flexibility)\n",
    "        return sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, zdim, num_steps, beta_1, beta_T):\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(zdim)\n",
    "        self.decoder = PointwiseNet(zdim)\n",
    "        self.schedule = VarianceSchedule(num_steps, beta_1, beta_T)\n",
    "\n",
    "    def encode(self, pos: torch.Tensor, batch: torch.Tensor):\n",
    "        return self.encoder(pos, batch)\n",
    "    \n",
    "    def decode(self, shape: tuple, ctx: torch.Tensor, batch: torch.Tensor, flex: float=0.0):\n",
    "        x_t = torch.randn(shape).to(ctx.device)\n",
    "        batch_size = int(batch.max() + 1)\n",
    "\n",
    "        for t in range(self.schedule.num_steps, 0, -1):\n",
    "            alpha = self.schedule.alphas[t]\n",
    "            alpha_bar = self.schedule.alpha_bars[t]\n",
    "            sigma = self.schedule.get_sigmas(t, flex)\n",
    "\n",
    "            c0 = 1.0 / torch.sqrt(alpha)\n",
    "            c1 = (1 - alpha) / torch.sqrt(1 - alpha_bar)\n",
    "\n",
    "            beta = self.schedule.betas[t].repeat(batch_size).view(-1, 1)\n",
    "            e_theta = self.decoder(x_t, t=beta, ctx=ctx, batch=batch)\n",
    "            \n",
    "            z = torch.randn_like(x_t) if t > 1 else torch.zeros_like(x_t)\n",
    "            x_t = c0 * (x_t - c1 * e_theta) + sigma * z\n",
    "\n",
    "        return x_t\n",
    "    \n",
    "\n",
    "    def forward(self, pos: torch.Tensor, batch: torch.Tensor):\n",
    "        z: torch.Tensor = self.encoder(pos, batch)\n",
    "        batch_size = z.size(0)\n",
    " \n",
    "        t = self.schedule.uniform_sample_t(batch_size)\n",
    "        alpha_bar = self.schedule.alpha_bars[t]\n",
    "        beta = self.schedule.betas[t]\n",
    "\n",
    "        c0 = torch.sqrt(alpha_bar)       \n",
    "        c1 = torch.sqrt(1 - alpha_bar)   \n",
    "        c0, c1 = c0[batch].view(-1, 1), c1[batch].view(-1, 1)\n",
    "\n",
    "        e_rand = torch.randn_like(pos)\n",
    "        e_theta = self.decoder(c0 * pos + c1 * e_rand, t=beta, ctx=z, batch=batch)\n",
    "\n",
    "        return e_theta, e_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.loss import chamfer_distance\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch import nn\n",
    "\n",
    "class CDLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, target, batch, reduction='mean'):\n",
    "        pred, target = to_dense_batch(pred, batch)[0], to_dense_batch(target, batch)[0]\n",
    "        return chamfer_distance(pred, target, batch_reduction=reduction)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_iterator(iterable):\n",
    "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
    "        for i, data in enumerate(inf_generator(train_loader)):\n",
    "    \"\"\"\n",
    "    iterator = iterable.__iter__()\n",
    "    while True:\n",
    "        try:\n",
    "            yield iterator.__next__()\n",
    "        except StopIteration:\n",
    "            iterator = iterable.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_scheduler(optimizer, start_epoch, end_epoch, start_lr, end_lr):\n",
    "    def lr_func(epoch):\n",
    "        if epoch <= start_epoch:\n",
    "            return 1.0\n",
    "        elif epoch <= end_epoch:\n",
    "            total = end_epoch - start_epoch\n",
    "            delta = epoch - start_epoch\n",
    "            frac = delta / total\n",
    "            return (1-frac) * 1.0 + frac * (end_lr / start_lr)\n",
    "        else:\n",
    "            return end_lr / start_lr\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import math\n",
    "\n",
    "\n",
    "def visualize_points(pos, c=None):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(pos[:, 0], pos[:, 1], pos[:, 2], c='blue' if c is None else c, s=3)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_batched_points(pos, batch, index, c=None):\n",
    "    tg, _ = to_dense_batch(pos, batch)\n",
    "    tg = tg[index]\n",
    "    visualize_points(tg.cpu())\n",
    "\n",
    "\n",
    "def visualize_batch_results(pos, newpos, batch, max_in_row=5):\n",
    "    pos, _ = to_dense_batch(pos, batch)\n",
    "    newpos, _ = to_dense_batch(newpos, batch)\n",
    "    n = pos.size(0)\n",
    "\n",
    "    num_rows = math.ceil(n / max_in_row)\n",
    "    num_cols = min(n, max_in_row)\n",
    "    print(num_rows, num_cols)\n",
    "\n",
    "    fig = plt.figure(figsize=(num_cols * 4, num_rows * 4))\n",
    "    for i in range(n):\n",
    "        ax = fig.add_subplot(2 * num_rows, num_cols, i+1, projection='3d')\n",
    "        pc = pos[i].cpu()\n",
    "        ax.scatter(pc[:, 0], pc[:, 1], pc[:, 2], c='red', s=3)\n",
    "        ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "    for i in range(n):\n",
    "        ax = fig.add_subplot(2 * num_rows, num_cols, i+num_cols * num_rows + 1, projection='3d')\n",
    "        pc = newpos[i].cpu()\n",
    "        ax.scatter(pc[:, 0], pc[:, 1], pc[:, 2], c='blue', s=3)\n",
    "        ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import MemoryHandler\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def get_logger(name, log_dir=None):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('[%(asctime)s::%(name)s::%(levelname)s] %(message)s')\n",
    "\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.DEBUG)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    if log_dir is not None:\n",
    "        file_handler = logging.FileHandler(os.path.join(log_dir, f'{name}.log'))\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    "        memory_handler = MemoryHandler(10, flushLevel=logging.ERROR, target=file_handler, flushOnClose=True)\n",
    "\n",
    "        logger.addHandler(memory_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def get_new_log_dir(root='./logs', postfix='', prefix=''):\n",
    "    log_dir = os.path.join(root, prefix + time.strftime('%Y_%m_%d__%H_%M_%S', time.localtime()) + postfix)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(log_dir, 'checkpoints'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(log_dir, 'samples'), exist_ok=True)\n",
    "    return log_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = get_new_log_dir(prefix='diffusion_')\n",
    "\n",
    "train_logger = get_logger('train', log_dir=log_dir)\n",
    "val_logger = get_logger('val', log_dir=log_dir)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model(zdim=train_dataset.num_classes, num_steps=1000, beta_1=1e-4, beta_T=0.02).to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()  # Define loss criterion.\n",
    "cd = CDLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_loss(it):\n",
    "    all_loss = 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        model.eval()\n",
    "        data = data.to(device)\n",
    "        \n",
    "        z = model.encode(data.pos, data.batch)\n",
    "        recons = model.decode(data.pos.size(), z, data.batch)\n",
    "        loss = cd(recons, data.pos, data.batch, reduction='sum')\n",
    "\n",
    "        val_logger.info(\"Validation:: Iteration: {}, Loss: {}\".format(i, loss.item()))\n",
    "        all_loss += loss.item()\n",
    "\n",
    "        if i == 0:\n",
    "            fig = visualize_batch_results(data.pos, recons, data.batch)\n",
    "            path = os.path.join(log_dir, 'samples', 'sample_{}.png'.format(it))\n",
    "            fig.savefig(path)\n",
    "            val_logger.info(\"Validation:: Saved sample image to {}\".format(path))\n",
    "    \n",
    "    val_logger.info(\"Validation:: Average Loss: {}\".format(all_loss / len(test_loader.dataset))) # type: ignore\n",
    "    return all_loss / len(test_loader.dataset) # type: ignore\n",
    "\n",
    "    \n",
    "\n",
    "def train():\n",
    "    ma_loss = 0\n",
    "    val_loss = validate_loss(0)\n",
    "    for i, data in enumerate(get_data_iterator(train_loader), 1):\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        model.train() \n",
    "        data = data.to(device)\n",
    "        \n",
    "        e_theta, e_rand = model(data.pos, data.batch)  # Forward pass.\n",
    "        loss = criterion(e_theta, e_rand)  # Loss computation.\n",
    "        \n",
    "        loss.backward()  # Backward pass.\n",
    "        optimizer.step()  # Update model parameters.\n",
    "        \n",
    "        ma_loss = 2 / (i + 1) * (loss.item() - ma_loss) + ma_loss\n",
    "        if i % 10000 == 0:\n",
    "            val_loss = validate_loss(i)\n",
    "            \n",
    "            train_logger.info(\"Train:: Saving epoch {} with loss {}\".format(i, val_loss))\n",
    "            torch.save({\n",
    "                'epoch': i,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'model_buffers': model.buffers(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, os.path.join(log_dir, 'checkpoints', 'checkpoint_{}.pt'.format(i)))\n",
    "        \n",
    "        train_logger.info(\"Train:: Iteration: {}, Loss: {}, MA Loss: {}\".format(i, loss.item(), ma_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
